{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Create an empty dictionary to store the images\n",
    "bills = {'MX020':[],'MX050':[],'MX100':[],'MX200':[],'MX500':[]}\n",
    "\n",
    "# define the target size for the images\n",
    "target_size = (600, 500)\n",
    "\n",
    "# load the image data into the dictionary and resize each image\n",
    "for filename in os.listdir('billetes'):\n",
    "    for bill in bills:\n",
    "        if bill in filename:\n",
    "            img = cv2.imread(os.path.join('billetes',filename))\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img, target_size)\n",
    "                bills[bill].append(img_resized)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = [] # feature vectors\n",
    "y = [] # labels\n",
    "for bill, imgs in bills.items():\n",
    "    for img in imgs:\n",
    "        X.append(img.flatten())\n",
    "        y.append(bill)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0) # 0 for the default webcam\n",
    "while True:\n",
    "    # preprocess each frame to extract the banknote region\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply adaptive thresholding to create a binary image\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # find the contour with the largest area (i.e., the banknote)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # get the bounding box of the banknote contour\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    # extract the banknote region from the frame\n",
    "    banknote = frame[y:y+h, x:x+w]\n",
    "\n",
    "    # apply thresholding, edge detection, or contour detection to extract the banknote region\n",
    "    # resize the extracted region to the same size as the training images\n",
    "    resized = cv2.resize(banknote, target_size)\n",
    "\n",
    "    # use the trained SVC model to predict the denomination of the banknote\n",
    "    prediction = model.predict(resized.flatten().reshape(1,-1))[0]\n",
    "\n",
    "    # draw the predicted denomination on the frame\n",
    "    cv2.putText(frame, prediction, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "    # display the frame on the screen\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # wait for the user to press the 'q' key to exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
